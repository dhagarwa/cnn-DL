epochs: 100  batch size: 128  reg_parameter: 0.0
Net (
  (conv1): Conv1d(1, 16, kernel_size=(4,), stride=(1,))
  (pool1): MaxPool1d (size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv1d(16, 16, kernel_size=(4,), stride=(2,))
  (conv3): Conv1d(16, 1, kernel_size=(20,), stride=(1,))
  (fc1): Linear (11 -> 11)
  (conv4): Conv1d(1, 16, kernel_size=(4,), stride=(1,))
  (pool2): MaxPool1d (size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv5): Conv1d(16, 16, kernel_size=(8,), stride=(1,))
  (error_function): MSELoss (
  )
)
Condition number: 1.93639231528
Initial Loss: 
 2566.0934
[torch.DoubleTensor of size 1]

Initial grad norm: Variable containing:
 28009.1603
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  0 ------------
Relative Loss: Variable containing:
1.00000e-02 *
  4.9766
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-03 *
  3.1214
[torch.DoubleTensor of size 1]

Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
--------------EPOCH  20 ------------
Relative Loss: Variable containing:
1.00000e-02 *
  4.4006
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-03 *
  5.1224
[torch.DoubleTensor of size 1]

Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 0.5
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
--------------EPOCH  40 ------------
Relative Loss: Variable containing:
1.00000e-02 *
  4.3705
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-04 *
  2.9453
[torch.DoubleTensor of size 1]

Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 0.5
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 0.5
Learning rate: 1
Learning rate: 0.25
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
--------------EPOCH  60 ------------
Relative Loss: Variable containing:
1.00000e-02 *
  4.3649
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-04 *
  2.9220
[torch.DoubleTensor of size 1]

Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
--------------EPOCH  80 ------------
Relative Loss: Variable containing:
1.00000e-02 *
  4.3637
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-05 *
  6.2662
[torch.DoubleTensor of size 1]

Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
Learning rate: 1
------------Printing TEST CASE ERROR:----------
Relative error: 1.5315105355347418
