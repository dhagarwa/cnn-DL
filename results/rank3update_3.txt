epochs: 40  batch size: 2128  reg_parameter: 0.0
Net (
  (r1_l1_conv1): Conv1d(1, 4, kernel_size=(1,), stride=(1,), bias=False)
  (r1_l1_pool1): MaxPool1d (size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (r1_l2_fc1): Linear (128 -> 10)
  (r1_l2_fc2): Linear (10 -> 10)
  (r1_l2_fc3): Linear (10 -> 128)
  (r1_l3_conv1): Conv1d(1, 4, kernel_size=(1,), stride=(1,), bias=False)
  (r2_l1_conv1): Conv1d(1, 4, kernel_size=(1,), stride=(1,), bias=False)
  (r2_l1_pool1): MaxPool1d (size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (r2_l2_fc1): Linear (64 -> 10)
  (r2_l2_fc2): Linear (10 -> 10)
  (r2_l2_fc3): Linear (10 -> 64)
  (r2_l2_exp): Conv1d(1, 2, kernel_size=(1,), stride=(1,), bias=False)
  (r2_l3_conv1): Conv1d(1, 4, kernel_size=(1,), stride=(1,), bias=False)
  (r2_l3_exp): Conv1d(1, 2, kernel_size=(1,), stride=(1,), bias=False)
  (r3_l1_conv1): Conv1d(1, 4, kernel_size=(1,), stride=(1,), bias=False)
  (r3_l1_pool1): MaxPool1d (size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (r3_l1_exp): Conv1d(1, 8, kernel_size=(1,), stride=(1,), bias=False)
  (r3_l2_fc1): Linear (32 -> 10)
  (r3_l2_fc2): Linear (10 -> 10)
  (r3_l2_fc3): Linear (10 -> 32)
  (r3_l2_exp): Conv1d(1, 4, kernel_size=(1,), stride=(1,), bias=False)
  (r3_l3_conv1): Conv1d(1, 4, kernel_size=(1,), stride=(1,), bias=False)
  (r3_l3_exp): Conv1d(1, 4, kernel_size=(1,), stride=(1,), bias=False)
  (error_function): MSELoss (
  )
)
[[ 2.49453317  1.33996279  0.90886593 ...,  0.7784805   1.45351545
   0.63155668]
 [ 1.37118487  2.0545053   1.07826998 ...,  0.4162418   1.30089365
   0.89539764]
 [ 0.77533231  0.41440316  1.59097242 ...,  0.32817385  0.97783501
   0.73507204]
 ..., 
 [ 0.73947593  0.47067701  0.55114095 ...,  1.3044098   0.85264226
   0.59876578]
 [ 1.08255604  0.8537811   0.50473694 ...,  0.83238673  2.35171125
   0.55262349]
 [ 1.63805786  1.3410152   1.10990155 ...,  0.73112367  1.63467826
   1.89917477]]
Condition number: 5740.2393948
Initial Loss: 
1.00000e+05 *
  6.4390
[torch.DoubleTensor of size 1]

Initial grad norm: Variable containing:
1.00000e+06 *
  1.3270
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  0 ------------
Absolute Loss: 50520.3251289897
Relative Loss: Variable containing:
1.00000e-02 *
  7.8459
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
 0.2489
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  1 ------------
Absolute Loss: 9710.081820122241
Relative Loss: Variable containing:
1.00000e-02 *
  1.5080
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-02 *
  4.4893
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  2 ------------
Absolute Loss: 7235.933902687354
Relative Loss: Variable containing:
1.00000e-02 *
  1.1238
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-02 *
  3.4565
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  3 ------------
Absolute Loss: 5984.661317082349
Relative Loss: Variable containing:
1.00000e-03 *
  9.2943
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-02 *
  1.2596
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  4 ------------
Absolute Loss: 3522.260183363081
Relative Loss: Variable containing:
1.00000e-03 *
  5.4702
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-02 *
  2.1615
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  5 ------------
Absolute Loss: 1060.729260777868
Relative Loss: Variable containing:
1.00000e-03 *
  1.6473
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-02 *
  1.8394
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  6 ------------
Absolute Loss: 395.8248741538566
Relative Loss: Variable containing:
1.00000e-04 *
  6.1473
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-02 *
  1.5185
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  7 ------------
Absolute Loss: 130.70971659389727
Relative Loss: Variable containing:
1.00000e-04 *
  2.0300
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-03 *
  7.8577
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  8 ------------
Absolute Loss: 40.96875145894284
Relative Loss: Variable containing:
1.00000e-05 *
  6.3626
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-03 *
  3.6707
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  9 ------------
Absolute Loss: 25.839395026494195
Relative Loss: Variable containing:
1.00000e-05 *
  4.0129
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-03 *
  2.8152
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  10 ------------
Absolute Loss: 12.207590616557278
Relative Loss: Variable containing:
1.00000e-05 *
  1.8959
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-03 *
  1.1810
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  11 ------------
Absolute Loss: 10.37185622355245
Relative Loss: Variable containing:
1.00000e-05 *
  1.6108
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-03 *
  1.0310
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  12 ------------
Absolute Loss: 7.1597738820423755
Relative Loss: Variable containing:
1.00000e-05 *
  1.1119
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-04 *
  8.0515
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  13 ------------
Absolute Loss: 5.376179320240662
Relative Loss: Variable containing:
1.00000e-06 *
  8.3494
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-04 *
  6.2549
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  14 ------------
Absolute Loss: 3.9695986539249124
Relative Loss: Variable containing:
1.00000e-06 *
  6.1649
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-04 *
  7.2945
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  15 ------------
Absolute Loss: 2.9066759118331946
Relative Loss: Variable containing:
1.00000e-06 *
  4.5142
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-04 *
  3.9923
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  16 ------------
Absolute Loss: 1.7119932850514563
Relative Loss: Variable containing:
1.00000e-06 *
  2.6588
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-04 *
  2.1042
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  17 ------------
Absolute Loss: 1.1453008157169906
Relative Loss: Variable containing:
1.00000e-06 *
  1.7787
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-04 *
  3.2057
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  18 ------------
Absolute Loss: 0.8269414741962403
Relative Loss: Variable containing:
1.00000e-06 *
  1.2843
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-04 *
  1.7313
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  19 ------------
Absolute Loss: 0.6002730491941546
Relative Loss: Variable containing:
1.00000e-07 *
  9.3224
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-04 *
  1.2443
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  20 ------------
Absolute Loss: 0.49405457559343713
Relative Loss: Variable containing:
1.00000e-07 *
  7.6728
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-04 *
  1.8526
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  21 ------------
Absolute Loss: 0.3893160152899911
Relative Loss: Variable containing:
1.00000e-07 *
  6.0462
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-04 *
  1.4532
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  22 ------------
Absolute Loss: 0.299029298120016
Relative Loss: Variable containing:
1.00000e-07 *
  4.6440
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-04 *
  1.3680
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  23 ------------
Absolute Loss: 0.23980509886765905
Relative Loss: Variable containing:
1.00000e-07 *
  3.7242
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-05 *
  8.2991
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  24 ------------
Absolute Loss: 0.19776231182384507
Relative Loss: Variable containing:
1.00000e-07 *
  3.0713
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-04 *
  1.2748
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  25 ------------
Absolute Loss: 0.16802739469889882
Relative Loss: Variable containing:
1.00000e-07 *
  2.6095
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-04 *
  1.0677
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  26 ------------
Absolute Loss: 0.15331353801946696
Relative Loss: Variable containing:
1.00000e-07 *
  2.3810
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-04 *
  1.2757
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  27 ------------
Absolute Loss: 0.13376982969350193
Relative Loss: Variable containing:
1.00000e-07 *
  2.0775
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-05 *
  3.6517
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  28 ------------
Absolute Loss: 0.10975046768601904
Relative Loss: Variable containing:
1.00000e-07 *
  1.7045
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-04 *
  1.4517
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  29 ------------
Absolute Loss: 0.08935573241809787
Relative Loss: Variable containing:
1.00000e-07 *
  1.3877
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-04 *
  1.0970
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  30 ------------
Absolute Loss: 0.07417356085292216
Relative Loss: Variable containing:
1.00000e-07 *
  1.1519
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-05 *
  2.5843
[torch.DoubleTensor of size 1]

Learning rate: 0.5
--------------EPOCH  31 ------------
Absolute Loss: 0.06310434302053486
Relative Loss: Variable containing:
1.00000e-08 *
  9.8003
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-04 *
  1.2315
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  32 ------------
Absolute Loss: 0.05339898136578534
Relative Loss: Variable containing:
1.00000e-08 *
  8.2930
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-05 *
  8.7809
[torch.DoubleTensor of size 1]

Learning rate: 0.5
--------------EPOCH  33 ------------
Absolute Loss: 0.04750642256229405
Relative Loss: Variable containing:
1.00000e-08 *
  7.3779
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-04 *
  1.0607
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  34 ------------
Absolute Loss: 0.0411381197653875
Relative Loss: Variable containing:
1.00000e-08 *
  6.3889
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-05 *
  3.2562
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  35 ------------
Absolute Loss: 0.03447547688278029
Relative Loss: Variable containing:
1.00000e-08 *
  5.3541
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-05 *
  4.0180
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  36 ------------
Absolute Loss: 0.02977298041458834
Relative Loss: Variable containing:
1.00000e-08 *
  4.6238
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-05 *
  2.8390
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  37 ------------
Absolute Loss: 0.02658144367491019
Relative Loss: Variable containing:
1.00000e-08 *
  4.1282
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-05 *
  2.4729
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  38 ------------
Absolute Loss: 0.02284265360038241
Relative Loss: Variable containing:
1.00000e-08 *
  3.5475
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-05 *
  1.8135
[torch.DoubleTensor of size 1]

Learning rate: 1
--------------EPOCH  39 ------------
Absolute Loss: 0.019849498776009143
Relative Loss: Variable containing:
1.00000e-08 *
  3.0827
[torch.DoubleTensor of size 1]

Relative Grad Norm: Variable containing:
1.00000e-05 *
  3.5437
[torch.DoubleTensor of size 1]

Weights norm 44.13304281392862
------------Printing TEST CASE ERROR:----------
Relative error: 0.0046922198219442185
